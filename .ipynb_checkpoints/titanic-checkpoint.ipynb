{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# load dataset\n",
    "titanic_train = pd.read_csv('../dataset/titanic/train.csv')\n",
    "titanic_test = pd.read_csv('../dataset/titanic/test.csv')\n",
    "\n",
    "titanic_train.info()\n",
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 5 columns):\n",
      "Pclass    891 non-null int64\n",
      "Sex       891 non-null int64\n",
      "Age       891 non-null float64\n",
      "SibSp     891 non-null int64\n",
      "Parch     891 non-null int64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 34.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 5 columns):\n",
      "Pclass    418 non-null int64\n",
      "Sex       418 non-null int64\n",
      "Age       418 non-null float64\n",
      "SibSp     418 non-null int64\n",
      "Parch     418 non-null int64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 16.4 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#make train dataset\n",
    "\n",
    "predict_col = ['Survived']\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "\n",
    "\n",
    "X_train = titanic_train[feature_cols]\n",
    "X_train['Sex'] = X_train['Sex'].apply(lambda x: int(x == 'male'))\n",
    "X_train['Age'].fillna(X_train['Age'].mean(),inplace=True)\n",
    "\n",
    "y_train = titanic_train[predict_col]\n",
    "\n",
    "X_test = titanic_test[feature_cols]\n",
    "X_test['Sex'] = X_test['Sex'].apply(lambda x: int(x == 'male'))\n",
    "X_test['Age'].fillna(X_test['Age'].mean(),inplace=True)\n",
    "\n",
    "x_test = pd.read_csv('../dataset/titanic/gender_submission.csv')['Survived']\n",
    "\n",
    "X_train.info()\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87       266\n",
      "          1       0.80      0.73      0.76       152\n",
      "\n",
      "avg / total       0.83      0.83      0.83       418\n",
      "\n",
      "[[238  28]\n",
      " [ 41 111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 5, min_samples_split = 5)\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = x_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "predicted = pd.DataFrame(predicted, columns = ['Survived'])\n",
    "predicted['PassengerId'] = pd.read_csv('../dataset/titanic/gender_submission.csv')['PassengerId']\n",
    "\n",
    "predicted = predicted.reindex(columns = ['PassengerId', 'Survived'])\n",
    "predicted.to_csv(\"./output/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.90      0.90       266\n",
      "          1       0.82      0.81      0.81       152\n",
      "\n",
      "avg / total       0.87      0.87      0.87       418\n",
      "\n",
      "[[239  27]\n",
      " [ 29 123]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = x_test\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "predicted = pd.DataFrame(predicted, columns = ['Survived'])\n",
    "predicted['PassengerId'] = pd.read_csv('../dataset/titanic/gender_submission.csv')['PassengerId']\n",
    "\n",
    "predicted = predicted.reindex(columns = ['PassengerId', 'Survived'])\n",
    "predicted.to_csv(\"./output/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = loan_2.reindex(columns= ['term_clean','grade_clean', 'annual_inc', 'loan_amnt', 'int_rate','purpose_clean','installment','loan_status_clean'])\n",
    "df.fillna(method= 'ffill').astype(int)\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "array = df.values\n",
    "y = df['loan_status_clean'].values\n",
    "imp.fit(array)\n",
    "array_imp = imp.transform(array)\n",
    "\n",
    "y2= y.reshape(1,-1)\n",
    "imp.fit(y2)\n",
    "y_imp= imp.transform(y2)\n",
    "X = array_imp[:,0:4]\n",
    "Y = array_imp[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import  BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('BNB', BernoulliNB()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('GBM', AdaBoostClassifier()))\n",
    "models.append(('NN', MLPClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
